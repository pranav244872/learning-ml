{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_9w-OrFJ53e",
        "outputId": "3f4e6535-0d85-4817-972c-080cb88862de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.empty(3) #1d vector with 3 elements initialized to 0\n",
        "y = torch.rand(2,2) #2d vector with 2 columns randomaly intitialized\n",
        "z = torch.empty(2,2, dtype=torch.int32) #integer\n",
        "a = torch.tensor([2,3])\n",
        "a[1].item() #returns 3 as number\n",
        "a[1] # returns 3 as tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor to numpy\n",
        "a.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w3C-TawfG_p",
        "outputId": "e04a5209-f59a-4410-8e83-ded01f769ea0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.from_numpy(a.numpy()) #numpy to tensor"
      ],
      "metadata": {
        "id": "AQmvbTUjfo3W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  x = torch.ones(5, device=device) #put tensor in the gpu\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device) #moves to gpu\n",
        "  #performs calculations much faster"
      ],
      "metadata": {
        "id": "pQcVUkTBf1-_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1,5, requires_grad=True) #means this requires gradient\n",
        "print(x)\n",
        "#whenever we do operations with this, pytorch will create a computational graph\n",
        "y = x+2\n",
        "print(y)\n",
        "\n",
        "z = torch.mm(torch.t(x),y)\n",
        "print(z)\n",
        "\n",
        "z.sum().backward() #grad can only be created for scalar outputs\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8civzkFvgULt",
        "outputId": "2152cd19-d57c-4ded-e0ad-ab4b0e8a0000"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5632,  0.7852, -0.3008, -0.2570, -0.5149]], requires_grad=True)\n",
            "tensor([[2.5632, 2.7852, 1.6992, 1.7430, 1.4851]], grad_fn=<AddBackward0>)\n",
            "tensor([[ 1.4435,  1.5685,  0.9569,  0.9816,  0.8363],\n",
            "        [ 2.0127,  2.1871,  1.3343,  1.3687,  1.1662],\n",
            "        [-0.7711, -0.8379, -0.5111, -0.5243, -0.4467],\n",
            "        [-0.6587, -0.7158, -0.4367, -0.4479, -0.3816],\n",
            "        [-1.3198, -1.4342, -0.8750, -0.8975, -0.7647]], grad_fn=<MmBackward0>)\n",
            "tensor([[10.5514, 10.5514, 10.5514, 10.5514, 10.5514]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#When we want to update weights that must not be part of gradient calculation\n",
        "#So we can use the following functions to stop gradient calculation\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():"
      ],
      "metadata": {
        "id": "rhDXkpVagwCC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Examples\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(1):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "\n",
        "  #before we do next iteration we have to empty the ccurrent gradients\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_4Dgt0RkNHp",
        "outputId": "e6397138-0f6e-4681-a4e4-757f8f49b969"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SomzRN0vlRj0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}